{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Read & Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv ('C:/Users/user/Desktop/Car_Price_Data.csv') # Read Data From CSV Using Pandas\n",
    "\n",
    "data = data.drop(columns=['Car Model']) # Drop Car Model Since It Is Not Important To Prediction\n",
    "data = data.drop(columns=['Car Make']) # Drop Car Make Since It Is Not Important To Prediction\n",
    "\n",
    "if 'Engine Size (L)' in data.columns:\n",
    "    data = data[pd.to_numeric(data['Engine Size (L)'], errors='coerce').notnull()] # Drop Any Engine Sizes That Are Electric Or Hybrid\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features And Output And Scale Them And Turn Them To Tensor Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Price (in USD)'], axis = 1) # These Are The Features\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].str.replace(',', '').astype(float) # Turn Everything To Type Float\n",
    "y = data['Price (in USD)'].str.replace(',', '').astype(float) # This Is The Output And We Turned Everything To Type Float\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X = scaler.fit_transform(X) # Scale Features\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()  # Scale Output\n",
    "\n",
    "X_tensor = torch.FloatTensor(X) # Turn Features To Tensor\n",
    "y_tensor = torch.FloatTensor(y) # Turn Output To Tensor\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor) # Create Tensor Dataset That Contains Both The Features And The Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset Into Training, Test, And Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data)) # Training Set Size\n",
    "dev_size = int(0.1 * len(data)) # Validation Set Size\n",
    "test_size = len(data) - train_size - dev_size # Test Set Size\n",
    "\n",
    "train_data, dev_data, test_data = random_split(dataset, [train_size, dev_size, test_size]) # Split And Shuffle Data\n",
    "\n",
    "batch_size = 64 # Batch Size\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True) # Load Training Data\n",
    "dev_loader = DataLoader(dev_data, batch_size=batch_size, shuffle=False) # Load Validation Data\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False) # Load Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 512) # Input Layer\n",
    "        self.bn1 = nn.BatchNorm1d(512) # Normalize Input Layer\n",
    "        self.fc2 = nn.Linear(512, 256) # Hidden Layer 1\n",
    "        self.bn2 = nn.BatchNorm1d(256) # Normalize Hidden Layer 1\n",
    "        self.fc3 = nn.Linear(256, 128) # Hidden Layer 2\n",
    "        self.bn3 = nn.BatchNorm1d(128) # Normalize Hidden Layer 2\n",
    "        self.fc4 = nn.Linear(128, 64) # Hidden Layer 3\n",
    "        self.bn4 = nn.BatchNorm1d(64) # Normalize Hidden Layer 3\n",
    "        self.fc5 = nn.Linear(64, 32) # Hidden Layer 4\n",
    "        self.bn5 = nn.BatchNorm1d(32) # Normalize Hidden Layer 4\n",
    "        self.fc6 = nn.Linear(32, 1) # Output Layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.leaky_relu(self.bn1(self.fc1(x))) # Forward Propogation On Input Layer\n",
    "        x = torch.nn.functional.leaky_relu(self.bn2(self.fc2(x))) # Forward Propogation On Hidden Layer 1\n",
    "        x = torch.nn.functional.leaky_relu(self.bn3(self.fc3(x))) # Forward Propogation On Hidden Layer 2\n",
    "        x = torch.nn.functional.leaky_relu(self.bn4(self.fc4(x))) # Forward Propogation On Hidden Layer 3\n",
    "        x = torch.nn.functional.leaky_relu(self.bn5(self.fc5(x))) # Forward Propogation On Hidden Layer 4\n",
    "        x = self.fc6(x) # Output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN() # Initialize Model\n",
    "criterion = nn.MSELoss() # Initialize Criterion\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001) # Initialize Gradient Descent\n",
    "\n",
    "epochs = 150 # Number Of Epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Set Model To Train Mode\n",
    "    running_loss = 0.0 # Initialize Loss\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.float(), labels.float().unsqueeze(1) # Convert Features And Labels To Float\n",
    "        optimizer.zero_grad() # Clear Gradients\n",
    "        outputs = model(features) # Forward Pass\n",
    "        loss = criterion(outputs, labels) # Compute Loss\n",
    "        loss.backward() # Backward Pass\n",
    "        optimizer.step() # Update Parameters\n",
    "        running_loss += loss.item() # Add Loss\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss/len(train_loader):.4f}') # Print Training Loss Per Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader):\n",
    "    model.eval() # Set Model To Evaluate Mode\n",
    "    mse_loss = 0.0 # Initialize Loss\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            features, labels = features.float(), labels.float().unsqueeze(1) # Convert Features And Labels To Float\n",
    "            outputs = model(features) # Forward Pass\n",
    "            loss = criterion(outputs, labels) # Compute Loss\n",
    "            mse_loss += loss.item() # Add Loss\n",
    "    return mse_loss / len(loader) # Return Average MSE Over All Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate & Print Validation & Test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mse = evaluate_model(dev_loader)\n",
    "print(f'Validation MSE: {validation_mse:.4f}')\n",
    "\n",
    "test_mse = evaluate_model(test_loader)\n",
    "print(f'Test MSE: {test_mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
